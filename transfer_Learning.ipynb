{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "# Keras\n",
    "from keras import backend as K\n",
    "from keras import __version__\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, AveragePooling2D, GlobalAveragePooling2D, Input, Flatten, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder_Path = r'C:\\Users\\Sachin13390\\Desktop\\NLP'\n",
    "\n",
    "IM_WIDTH, IM_HEIGHT = 299, 299 #fixed size for InceptionV3\n",
    "\n",
    "image_Dir_Not_Valid_Error = \"Input image directory not valid - \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Sub_Folders_Count_From_Root_Folders(Folder_Path):\n",
    "    return (len(next(os.walk(Folder_Path))[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_If_Directory_Exists(dir_Path):\n",
    "    if os.path.exists(dir_Path):\n",
    "        return True\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Train_And_Test_Generator(train_image_dir, test_image_dir, FLAGS):\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "                                        rotation_range = 20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                        rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True,\n",
    "                                        vertical_flip=True, fill_mode='nearest')\n",
    "\n",
    "    test_datagen = ImageDataGenerator(\n",
    "                                        rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                        rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True,\n",
    "                                        vertical_flip=True, fill_mode='nearest')\n",
    "\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "                                                        train_image_dir,  target_size=(IM_WIDTH, IM_HEIGHT), \n",
    "                                                        batch_size=32,  class_mode='categorical')\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "                                                        test_image_dir,  target_size=(IM_WIDTH, IM_HEIGHT), \n",
    "                                                        batch_size=32,  class_mode='categorical')\n",
    "\n",
    "    return (train_generator, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_New_Layer_Model(base_Model, no_Of_Classes):\n",
    "    \n",
    "    x = base_Model.output\n",
    "    x = AveragePooling2D((8, 8), border_mode='valid', name='avg_pool')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    predictions = Dense(no_Of_Classes, activation='softmax')(x)\n",
    "    model = Model(input=base_Model.input, output=predictions)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Model(FLAGS):\n",
    "    \n",
    "    if not os.path.exists(FLAGS.train_image_dir):\n",
    "        print(image_Dir_Not_Valid_Error, FLAGS.train_image_dir)\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(FLAGS.test_image_dir):\n",
    "        return (image_Dir_Not_Valid_Error, FLAGS.test_image_dir)\n",
    "    \n",
    "    \n",
    "    \n",
    "    no_Of_Classes = Get_Sub_Folders_Count_From_Root_Folders(FLAGS.train_image_dir) \n",
    "    \n",
    "    \n",
    "    train_generator, test_generator = Get_Train_And_Test_Generator(\n",
    "                                                                    FLAGS.train_image_dir,\n",
    "                                                                    FLAGS.test_image_dir,\n",
    "                                                                    FLAGS)\n",
    "    \n",
    "    input_tensor = ''\n",
    "    if(K.image_dim_ordering() == 'th'): # For tensorflow\n",
    "        input_tensor = Input(shape=(3, IM_WIDTH, IM_HEIGHT))\n",
    "    else:\n",
    "        input_tensor = Input(shape=(IM_WIDTH, IM_HEIGHT, 3))\n",
    "        \n",
    "        \n",
    "    # Get Inception model from Keras\n",
    "    base_model = InceptionV3(input_tensor = input_tensor, weights = 'imagenet', include_top = False)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = Get_New_Layer_Model(base_model, no_Of_Classes)\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit_generator(train_generator,\n",
    "                        steps_per_epoch = 48,\n",
    "                        epochs = FLAGS.how_many_training_steps, validation_data = test_generator, validation_steps = 16)\n",
    "    \n",
    "    frozen_graph = freeze_session(K.get_session(),\n",
    "                                  output_names=[out.op.name for out in model.outputs])\n",
    "    \n",
    "    tf.train.write_graph(frozen_graph, \"some_directory\", \"ZZZZZZZ.pb\", as_text=False)\n",
    "    \n",
    "#     model.save(FLAGS.output_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "      '--train_image_dir',\n",
    "      type=str,\n",
    "      default='',\n",
    "      help='Path to train folders of labeled images.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--test_image_dir',\n",
    "      type=str,\n",
    "      default='',\n",
    "      help='Path to test folders of labeled images.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--output_graph',\n",
    "      type=str,\n",
    "      default='/tmp/output_graph.pb',\n",
    "      help='Where to save the trained graph.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--output_labels',\n",
    "      type=str,\n",
    "      default='/tmp/output_labels.txt',\n",
    "      help='Where to save the trained graph\\'s labels.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--summaries_dir',\n",
    "      type=str,\n",
    "      default='/tmp/retrain_logs',\n",
    "      help='Where to save summary logs for TensorBoard.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--how_many_training_steps',\n",
    "      type=int,\n",
    "      default=4000,\n",
    "      help='How many training steps to run before ending.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--learning_rate',\n",
    "      type=float,\n",
    "      default=0.01,\n",
    "      help='How large a learning rate to use when training.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--testing_percentage',\n",
    "      type=int,\n",
    "      default=10,\n",
    "      help='What percentage of images to use as a test set.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--validation_percentage',\n",
    "      type=int,\n",
    "      default=10,\n",
    "      help='What percentage of images to use as a validation set.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--eval_step_interval',\n",
    "      type=int,\n",
    "      default=10,\n",
    "      help='How often to evaluate the training results.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--train_batch_size',\n",
    "      type=int,\n",
    "      default=100,\n",
    "      help='How many images to train on at a time.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--test_batch_size',\n",
    "      type=int,\n",
    "      default=-1,\n",
    "      help=\"\"\"\\\n",
    "      How many images to test on. This test set is only used once, to evaluate\n",
    "      the final accuracy of the model after training completes.\n",
    "      A value of -1 causes the entire test set to be used, which leads to more\n",
    "      stable results across runs.\\\n",
    "      \"\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--validation_batch_size',\n",
    "      type=int,\n",
    "      default=100,\n",
    "      help=\"\"\"\\\n",
    "      How many images to use in an evaluation batch. This validation set is\n",
    "      used much more often than the test set, and is an early indicator of how\n",
    "      accurate the model is during training.\n",
    "      A value of -1 causes the entire validation set to be used, which leads to\n",
    "      more stable results across training iterations, but may be slower on large\n",
    "      training sets.\\\n",
    "      \"\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--print_misclassified_test_images',\n",
    "      default=False,\n",
    "      help=\"\"\"\\\n",
    "      Whether to print out a list of all misclassified test images.\\\n",
    "      \"\"\",\n",
    "      action='store_true'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--model_dir',\n",
    "      type=str,\n",
    "      default='/tmp/imagenet',\n",
    "      help=\"\"\"\\\n",
    "      Path to classify_image_graph_def.pb,\n",
    "      imagenet_synset_to_human_label_map.txt, and\n",
    "      imagenet_2012_challenge_label_map_proto.pbtxt.\\\n",
    "      \"\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--bottleneck_dir',\n",
    "      type=str,\n",
    "      default='/tmp/bottleneck',\n",
    "      help='Path to cache bottleneck layer values as files.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--final_tensor_name',\n",
    "      type=str,\n",
    "      default='final_result',\n",
    "      help=\"\"\"\\\n",
    "      The name of the output classification layer in the retrained graph.\\\n",
    "      \"\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--flip_left_right',\n",
    "      default=False,\n",
    "      help=\"\"\"\\\n",
    "      Whether to randomly flip half of the training images horizontally.\\\n",
    "      \"\"\",\n",
    "      action='store_true'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--random_crop',\n",
    "      type=int,\n",
    "      default=0,\n",
    "      help=\"\"\"\\\n",
    "      A percentage determining how much of a margin to randomly crop off the\n",
    "      training images.\\\n",
    "      \"\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--random_scale',\n",
    "      type=int,\n",
    "      default=0,\n",
    "      help=\"\"\"\\\n",
    "      A percentage determining how much to randomly scale up the size of the\n",
    "      training images by.\\\n",
    "      \"\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "      '--random_brightness',\n",
    "      type=int,\n",
    "      default=0,\n",
    "      help=\"\"\"\\\n",
    "      A percentage determining how much to randomly multiply the training image\n",
    "      input pixels up or down by.\\\n",
    "      \"\"\"\n",
    "    )\n",
    "    \n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    \n",
    "    train_Model(FLAGS)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ###################### Testing ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_File_Path = r'C:\\Users\\Sachin13390\\Desktop\\Transfer_learning\\Trained_Model\\5_Epoch_Trained_Model.pb'\n",
    "# image_Folder_Path = r'C:\\Users\\Sachin13390\\Desktop\\Transfer_learning\\Test_Images'\n",
    "# image_Path = r'C:\\Users\\Sachin13390\\Desktop\\Transfer_learning\\Test_Images\\7.jpg'\n",
    "\n",
    "# model = load_model(model_File_Path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (1,14):\n",
    "#     image_Path = os.path.join(image_Folder_Path, (str(i) + '.jpg'))\n",
    "# #     print(image_Path)\n",
    "#     image = cv2.imread(image_Path)\n",
    "#     image = cv2.resize(image, (299, 299))\n",
    "# #     cv2.imshow('image',image)\n",
    "# #     cv2.waitKey(0)\n",
    "#     image = image.reshape(1, 299, 299, 3)\n",
    "#     image = image/255\n",
    "\n",
    "#     print(np.;\\argmax(model.predict(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python transfer_Learning.py --train_image_dir=C:\\\\Users\\\\Sachin13390\\\\Desktop\\\\Transfer_learning\\\\Data_CNN\\\\Train  --test_image_dir=C:\\\\Users\\\\Sachin13390\\\\Desktop\\\\Transfer_learning\\\\Data_CNN\\\\Test  --output_graph=C:\\\\Users\\\\Sachin13390\\\\Desktop\\\\Transfer_learning\\\\Trained_Model\\\\trained_Model.h5  --how_many_training_steps=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
