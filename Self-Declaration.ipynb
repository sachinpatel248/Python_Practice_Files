{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sachin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fuzzywuzzy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-254da9d9ed48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfuzzywuzzy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fuzzywuzzy'"
     ]
    }
   ],
   "source": [
    "from  scipy import ndimage\n",
    "import math\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "from math import atan2, pi\n",
    "import string\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from keras.models import Sequential, load_model\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "from nltk.tag import pos_tag\n",
    "import json\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFilePath =r'C:\\Users\\sachin\\Desktop\\Self-Declaration.jpg'\n",
    "\n",
    "KERAS_Alphabet_model_File_Path = r'C:\\Users\\sachin\\Desktop\\Keras_Alphabet_Model.h5'\n",
    "Alphabet_Mapping_List = list(string.ascii_uppercase)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "index = 0\n",
    "global counts,X,Y,W,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    KERAS_Alphabet_Model = load_model(KERAS_Alphabet_model_File_Path)\n",
    "except:\n",
    "    KERAS_Model = load_model(KERAS_model_File_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Processed_Image(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blur = cv2.GaussianBlur(gray_image,(5,5),0)\n",
    "    ret3,Otsu_Threshold_GaussianBlur_Image = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    Otsu_Threshold_GaussianBlur_Image = cv2.bitwise_not(Otsu_Threshold_GaussianBlur_Image)\n",
    "\n",
    "    closing = cv2.morphologyEx(Otsu_Threshold_GaussianBlur_Image, cv2.MORPH_CLOSE, kernel)\n",
    "    #cv2.imwrite(r'C:\\Users\\sachin13390\\Desktop\\closing.jpg',closing)\n",
    "\n",
    "    return closing\n",
    "\n",
    "\n",
    "\n",
    "def Get_Dilated_Image(image, number):\n",
    "    kernel = np.ones((5,number),np.uint8)\n",
    "    img_dilation = cv2.dilate(image, kernel, iterations=3)\n",
    "    #cv2.imwrite(r'C:\\Users\\sachin13390\\Desktop\\img_dilation_'+str(index)+'.jpg',img_dilation)\n",
    "\n",
    "    return img_dilation\n",
    "        \n",
    "\n",
    "def Get_Countours(input_Image):\n",
    "    temp_image, contours, hierarchy = cv2.findContours(input_Image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return contours\n",
    "\n",
    "\n",
    "def Sort_Countours(cnts, method=\"left-to-right\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 0\n",
    "\n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "\n",
    "    # handle if we are sorting against the y-coordinate rather than\n",
    "    # the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "\n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "                                        key=lambda b:b[1][i], reverse=reverse))\n",
    "\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts)\n",
    "\n",
    "def Draw_Contours(Image, Contours):\n",
    "    for cnt in Contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        #print (str(x) + \" - \" + str(y)+ \" - \" + str(w) + \" - \" + str(h))\n",
    "        cv2.rectangle(Image,(x,y),(x+w,y+h),(0,255,255),1)\n",
    "    cv2.imwrite(r'C:\\Users\\sachin13390\\Desktop\\croppedrect.jpg',Image)   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getNewResizedImage(input_Image, Image_Size):\n",
    "    height,width = input_Image.shape\n",
    "    #print (height, width)\n",
    "\n",
    "    if width > height:\n",
    "        aspect_Ratio = (float)(width/height)\n",
    "        width = 20\n",
    "        height = round(width/aspect_Ratio)\n",
    "    else:\n",
    "        aspect_Ratio = (float)(height/width)\n",
    "        height = 20\n",
    "        width = round(height/aspect_Ratio)\n",
    "        \n",
    "    input_Image = cv2.resize(input_Image, (width,height), interpolation = cv2.INTER_AREA )\n",
    "    \n",
    "    height,width = input_Image.shape\n",
    "    \n",
    "    number_Of_Column_To_Add = 28-width\n",
    "    temp_Column = np.zeros( (height , int(number_Of_Column_To_Add/2)), dtype = np.uint8)\n",
    "    input_Image = np.append(temp_Column, input_Image, axis=1)\n",
    "    input_Image = np.append(input_Image, temp_Column, axis=1)\n",
    "\n",
    "\n",
    "    height,width = input_Image.shape\n",
    "\n",
    "    number_Of_Row_To_Add = 28-height\n",
    "    temp_Row= np.zeros( (int(number_Of_Row_To_Add/2) , width ), dtype = np.uint8)\n",
    "    input_Image = np.concatenate((temp_Row,input_Image))\n",
    "    input_Image = np.concatenate((input_Image,temp_Row))\n",
    "\n",
    "    return cv2.resize(input_Image, (Image_Size,Image_Size), interpolation = cv2.INTER_AREA )\n",
    "\n",
    "\n",
    "def Get_Average_Space_From_Image_Line(contours):\n",
    "    total_space = 0\n",
    "    number_Of_Character = 0\n",
    "    last_Point = -1\n",
    "    avg_Space = 0\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        #print (x,y,w,h)\n",
    "\n",
    "        if w > 30 and h > 30 and x > 0 and y > 0:\n",
    "            if last_Point == -1:\n",
    "                last_Point = 0\n",
    "            else:\n",
    "                total_space = total_space + ( x - last_Point )\n",
    "            last_Point = x + w\n",
    "\n",
    "            number_Of_Character = number_Of_Character + 1\n",
    "\n",
    "    avg_Space = int (total_space/number_Of_Character)\n",
    "\n",
    "    total_space = 0\n",
    "    last_Point = -1\n",
    "    number_Of_Character = 0\n",
    "\n",
    "##    for cnt in contours:\n",
    "##        x,y,w,h = cv2.boundingRect(cnt)\n",
    "##\n",
    "##        if w > 30 and h > 30 and x > 0 and y > 0:\n",
    "##            if last_Point == -1:\n",
    "##                last_Point = 0\n",
    "##            else:\n",
    "##                space = ( (x + w) - last_Point )\n",
    "##                if space < avg_Space:\n",
    "##                    total_space = total_space + space\n",
    "##                    number_Of_Character = number_Of_Character + 1\n",
    "##            last_Point = x + w\n",
    "##            \n",
    "##    avg_Space = int (total_space/number_Of_Character)\n",
    "\n",
    "    return avg_Space\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Get_Text_From_Image(Image, contours):\n",
    "    global count,X,Y,W,H, list_Character_Positions\n",
    "    KERAS_Alphabet_Prediction = ''\n",
    "\n",
    "    total_space = 0\n",
    "    number_Of_Character = 0\n",
    "    last_Point = -1\n",
    "\n",
    "    #avg_Space = Get_Average_Space_From_Image_Line(contours)\n",
    "    last_Point = -1\n",
    "    total_space = 0\n",
    "    #print (avg_Space)\n",
    "    \n",
    "    Word_Dilated_Image = Get_Dilated_Image(Image,20)\n",
    "    Word_Contours = Get_Countours(Word_Dilated_Image)\n",
    "    Word_Contours = Sort_Countours(Word_Contours,\"left-to-right\")\n",
    "    last_Word_Contour_Index = 0\n",
    "    Word_X, Word_Y, Word_W, Word_H = cv2.boundingRect(Word_Contours[last_Word_Contour_Index])\n",
    "    last_Word_Contour_Max_X_Range = Word_X + Word_W\n",
    "    # i.e X + W\n",
    "            \n",
    "\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        give_Space = False\n",
    "        #print (x,y,w,h)\n",
    "\n",
    "        # Reject if Contour is not of desired size (too small)\n",
    "        if w > 30 and h > 30 and x > 0 and y > 0:\n",
    "\n",
    "#             ## Spacing based on average space between character\n",
    "#             if last_Point == -1:\n",
    "#                 last_Point = 0\n",
    "#             else:\n",
    "#                 total_space = ( x - last_Point )\n",
    "\n",
    "#             last_Point = x + w\n",
    "\n",
    "#             if total_space > (avg_Space*1.3):\n",
    "#                 give_Space = True\n",
    "            \n",
    "            ## Spacing based on word formation\n",
    "            if x > last_Word_Contour_Max_X_Range:\n",
    "                give_Space = True\n",
    "                last_Word_Contour_Index = last_Word_Contour_Index + 1\n",
    "                Word_X, Word_Y, Word_W, Word_H = cv2.boundingRect(Word_Contours[last_Word_Contour_Index])\n",
    "                last_Word_Contour_Max_X_Range = Word_X + Word_W\n",
    "                # i.e X + W\n",
    "            \n",
    "    \n",
    "                \n",
    "            if give_Space == True:\n",
    "                KERAS_Alphabet_Prediction = KERAS_Alphabet_Prediction + \" \"\n",
    "                list_Character_Positions.append((-1,-1,-1,-1,\" \"))\n",
    "                \n",
    "\n",
    "            resize_image = getNewResizedImage(Image[y:y+h, x:x+w] , 28)\n",
    "            path = r'C:\\Users\\sachin13390\\Desktop\\Images\\\\' + str(count)+'.png'\n",
    "            cv2.imwrite(path,resize_image)\n",
    "            resize_image = resize_image.flatten()\n",
    "            count = count + 1\n",
    "\n",
    "            temp_Index = int(KERAS_Alphabet_Model.predict_classes(resize_image.reshape(1,784)/255.0)[0])\n",
    "            alphabet_probability = (KERAS_Alphabet_Model.predict_proba(resize_image.reshape(1,784)/255.0))\n",
    "            sort_alphabet_probability = -np.sort(-alphabet_probability)\n",
    "\n",
    "            KERAS_Alphabet_Prediction = KERAS_Alphabet_Prediction + Alphabet_Mapping_List[int(temp_Index)]\n",
    "\n",
    "            list_Character_Positions.append((x+X,y+Y,w,h,str(Alphabet_Mapping_List[int(temp_Index)])))\n",
    "\n",
    "##            if sort_alphabet_probability[0,0] > 0.99:\n",
    "##                KERAS_Alphabet_Prediction = KERAS_Alphabet_Prediction + Alphabet_Mapping_List[int(temp_Index)]\n",
    "##            else:\n",
    "##                alternate_Probable_Alphabet = Alphabet_Mapping_List[int(np.where(alphabet_probability == sort_alphabet_probability[0,1])[1][0])]\n",
    "##                KERAS_Alphabet_Prediction = KERAS_Alphabet_Prediction + \"[\" + Alphabet_Mapping_List[int(temp_Index)] + \",\" + alternate_Probable_Alphabet + \"]\"\n",
    "\n",
    "    list_Character_Positions.append((-1,-1,-1,-1,\" \"))\n",
    "\n",
    "    return KERAS_Alphabet_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(imageFilePath)\n",
    "image = Get_Processed_Image(image)\n",
    "image_With_Lines = Get_Dilated_Image(image, 60)\n",
    "\n",
    "contours = Get_Countours(image_With_Lines)\n",
    "contours = Sort_Countours(contours, \"top-to-bottom\")\n",
    "\n",
    "Draw_Contours(cv2.imread(imageFilePath),contours)\n",
    "Predicted_Text = ''\n",
    "temp_Index = ''\n",
    "global list_Character_Positions\n",
    "X=Y=W=H=0\n",
    "count = 20\n",
    "list_Character_Positions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KERAS_Alphabet_Predict \n",
      " MY NAME IS HEMANT SMELAR I AM WORKING JN MASTEK FROM LAST SIX TEARS CURRENTLY WORKING POR JNDIAN AND UR GOVERNMENT PROIECT\n"
     ]
    }
   ],
   "source": [
    "counts = 0\n",
    "index = 0\n",
    "Predicted_Text = ''\n",
    "for line_Area in contours:\n",
    "    counts = counts + 1\n",
    "    x,y,w,h = cv2.boundingRect(line_Area)\n",
    "    X,Y,W,H = x,y,w,h\n",
    "    line_Image = image[y:y+h, x:x+w]\n",
    "    path = r'C:\\Users\\sachin13390\\Desktop\\Images\\\\' + str(counts)+'.png'\n",
    "    cv2.imwrite(path,line_Image)\n",
    "\n",
    "    line_Contours = Get_Countours(line_Image)\n",
    "    line_Contours = Sort_Countours(line_Contours,\"left-to-right\")\n",
    "    #Draw_Contours(line_Image,line_Contours)\n",
    "    \n",
    "    text = (Get_Text_From_Image(line_Image, line_Contours))\n",
    "    #print (text)\n",
    "\n",
    "    Predicted_Text = Predicted_Text + \" \" + text\n",
    "\n",
    "\n",
    "print('KERAS_Alphabet_Predict \\n' + Predicted_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hemant\n",
      "Smelar\n",
      "Jn\n",
      "Mastek\n",
      "Six\n",
      "Tears\n",
      "Currently\n",
      "Working\n",
      "Por\n",
      "Jndian\n",
      "Ur\n",
      "Government\n",
      "Proiect\n"
     ]
    }
   ],
   "source": [
    "tagged_sent = pos_tag(Predicted_Text.title().split())\n",
    "\n",
    "propernouns = [word for word,pos in tagged_sent if pos == 'NNP']\n",
    "\n",
    "for names in propernouns:\n",
    "    print (names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[378, 187, 81, 61, \"M\"], [480, 188, 59, 69, \"Y\"], [-1, -1, -1, -1, \" \"], [630, 191, 59, 66, \"N\"], [718, 184, 52, 67, \"A\"], [792, 192, 84, 59, \"M\"], [904, 187, 49, 68, \"E\"], [-1, -1, -1, -1, \" \"], [1026, 178, 48, 72, \"I\"], [1095, 183, 47, 66, \"S\"], [-1, -1, -1, -1, \" \"], [1245, 175, 53, 72, \"H\"], [1318, 176, 50, 73, \"E\"], [1385, 175, 99, 66, \"M\"], [1523, 171, 78, 73, \"A\"], [1617, 185, 72, 66, \"N\"], [1705, 186, 77, 62, \"T\"], [-1, -1, -1, -1, \" \"], [1890, 188, 81, 63, \"S\"], [1984, 199, 62, 65, \"M\"], [2073, 192, 51, 66, \"E\"], [2158, 198, 63, 65, \"L\"], [2237, 191, 62, 74, \"A\"], [2320, 181, 94, 76, \"R\"], [-1, -1, -1, -1, \" \"], [363, 360, 67, 67, \"I\"], [-1, -1, -1, -1, \" \"], [502, 370, 71, 70, \"A\"], [592, 377, 94, 67, \"M\"], [-1, -1, -1, -1, \" \"], [827, 383, 92, 62, \"W\"], [954, 390, 46, 53, \"O\"], [1029, 378, 74, 67, \"R\"], [1123, 381, 72, 63, \"K\"], [1213, 376, 61, 70, \"I\"], [1306, 385, 77, 62, \"N\"], [1417, 385, 57, 72, \"G\"], [-1, -1, -1, -1, \" \"], [1552, 377, 63, 67, \"J\"], [1658, 388, 73, 69, \"N\"], [-1, -1, -1, -1, \" \"], [1865, 379, 112, 70, \"M\"], [2013, 379, 56, 66, \"A\"], [2080, 382, 60, 54, \"S\"], [2160, 382, 48, 59, \"T\"], [2230, 382, 47, 57, \"E\"], [2309, 379, 74, 79, \"K\"], [-1, -1, -1, -1, \" \"], [401, 573, 65, 97, \"F\"], [490, 584, 70, 76, \"R\"], [584, 600, 38, 61, \"O\"], [645, 595, 101, 61, \"M\"], [-1, -1, -1, -1, \" \"], [895, 586, 46, 69, \"L\"], [979, 584, 67, 73, \"A\"], [1083, 591, 60, 62, \"S\"], [1158, 593, 58, 58, \"T\"], [-1, -1, -1, -1, \" \"], [1343, 592, 54, 62, \"S\"], [1420, 592, 51, 69, \"I\"], [1482, 605, 56, 64, \"X\"], [-1, -1, -1, -1, \" \"], [1644, 597, 69, 84, \"T\"], [1733, 594, 64, 74, \"E\"], [1825, 595, 59, 64, \"A\"], [1911, 585, 70, 74, \"R\"], [2008, 593, 40, 65, \"S\"], [-1, -1, -1, -1, \" \"], [418, 811, 65, 68, \"C\"], [502, 819, 67, 57, \"U\"], [609, 808, 72, 73, \"R\"], [709, 805, 71, 73, \"R\"], [801, 815, 59, 59, \"E\"], [894, 817, 80, 67, \"N\"], [988, 814, 60, 64, \"T\"], [1080, 813, 47, 68, \"L\"], [1125, 816, 73, 91, \"Y\"], [-1, -1, -1, -1, \" \"], [1352, 797, 121, 87, \"W\"], [1502, 804, 48, 69, \"O\"], [1572, 799, 71, 81, \"R\"], [1666, 807, 49, 79, \"K\"], [1733, 801, 55, 87, \"I\"], [1801, 812, 67, 70, \"N\"], [1893, 803, 54, 85, \"G\"], [-1, -1, -1, -1, \" \"], [2136, 774, 52, 100, \"P\"], [2211, 783, 48, 69, \"O\"], [2298, 763, 103, 85, \"R\"], [-1, -1, -1, -1, \" \"], [397, 1032, 117, 75, \"J\"], [522, 1046, 82, 68, \"N\"], [637, 1041, 78, 82, \"D\"], [734, 1043, 54, 70, \"I\"], [813, 1052, 47, 69, \"A\"], [891, 1054, 74, 67, \"N\"], [-1, -1, -1, -1, \" \"], [1111, 1054, 65, 72, \"A\"], [1187, 1055, 69, 62, \"N\"], [1286, 1045, 60, 71, \"D\"], [-1, -1, -1, -1, \" \"], [1463, 1049, 63, 63, \"U\"], [1573, 1046, 77, 60, \"R\"], [-1, -1, -1, -1, \" \"], [1757, 1027, 75, 78, \"G\"], [1853, 1024, 31, 70, \"O\"], [1910, 1023, 54, 66, \"V\"], [1990, 1015, 39, 65, \"E\"], [2045, 1004, 67, 82, \"R\"], [2122, 1011, 68, 62, \"N\"], [2214, 997, 90, 74, \"M\"], [2327, 998, 50, 59, \"E\"], [2408, 998, 61, 72, \"N\"], [2484, 995, 68, 68, \"T\"], [-1, -1, -1, -1, \" \"], [438, 1295, 50, 84, \"P\"], [501, 1309, 89, 71, \"R\"], [598, 1313, 37, 63, \"O\"], [656, 1304, 64, 91, \"I\"], [755, 1316, 65, 71, \"E\"], [851, 1318, 50, 64, \"C\"], [897, 1319, 66, 70, \"T\"], [-1, -1, -1, -1, \" \"]]\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(imageFilePath)\n",
    "string_Output = \"\"\n",
    "for char in list_Character_Positions:\n",
    "    string_Output = string_Output + char[4]\n",
    "    #print (char[0],char[1],char[2],char[3],char[4])\n",
    "    x,y,w,h = char[0],char[1],char[2],char[3]\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(0,0,0),1)\n",
    "cv2.imwrite(r'C:\\Users\\sachin13390\\Desktop\\Final.jpg',image)\n",
    "\n",
    "json_list_Character_Positions = json.dumps(list_Character_Positions)\n",
    "print (json_list_Character_Positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HEMANT', 'MASTEK', 'PROJECT', 'SHELAR', 'WORKING', 'KIOSK']\n"
     ]
    }
   ],
   "source": [
    "def Get_Words_To_Hide_In_List(words_To_Hide):\n",
    "    words_To_Hide = words_To_Hide.upper().strip().replace('  ',' ')\n",
    "    \n",
    "    while '  ' in words_To_Hide:\n",
    "        words_To_Hide =  words_To_Hide.replace('  ',' ')\n",
    "    list_Words_To_Hide = words_To_Hide.split(\" \")\n",
    "    \n",
    "    return list_Words_To_Hide\n",
    "\n",
    "#words_To_Hide = input(\"Enter word to hide \")\n",
    "words_To_Hide = \"  Hemant  MASTEK  Project    Shelar    Working  kiosk\"\n",
    "\n",
    "list_Words_To_Hide = Get_Words_To_Hide_In_List(words_To_Hide)\n",
    "print (list_Words_To_Hide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "global word_Matching_Thresh_Value\n",
    "word_Matching_Thresh_Value = 80\n",
    "\n",
    "def Get_Similar_List_Of_Words_To_Hide(list_Words_To_Hide):\n",
    "    list_Similar_Words = []\n",
    "    list_Predicted_Text_Words = string_Output.split(\" \")\n",
    "    \n",
    "    for word_To_Hide in list_Words_To_Hide:\n",
    "        \n",
    "        for predicted_Word in list_Predicted_Text_Words:\n",
    "            \n",
    "            word_Probability = fuzz.ratio(word_To_Hide,predicted_Word)\n",
    "            \n",
    "            if word_Probability > word_Matching_Thresh_Value:\n",
    "                list_Similar_Words.append(predicted_Word)\n",
    "                #print (word_To_Hide,predicted_Word)\n",
    "                \n",
    "    return list_Similar_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HEMANT', 'MASTEK', 'PROJECT', 'SHELAR', 'WORKING', 'KIOSK', 'PROIECT', 'SMELAR']\n"
     ]
    }
   ],
   "source": [
    "list_Similar_Words = Get_Similar_List_Of_Words_To_Hide(list_Words_To_Hide)\n",
    "\n",
    "for similar_Word in list_Similar_Words:\n",
    "    if not similar_Word in list_Words_To_Hide:\n",
    "        list_Words_To_Hide.append(similar_Word)\n",
    "\n",
    "print (list_Words_To_Hide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEMANT 1\n",
      "MASTEK 1\n",
      "PROJECT 0\n",
      "SHELAR 0\n",
      "WORKING 2\n",
      "KIOSK 0\n",
      "PROIECT 1\n",
      "SMELAR 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(imageFilePath)\n",
    "\n",
    "for word in list_Words_To_Hide:\n",
    "\n",
    "    count_Of_Word = string_Output.count(word)\n",
    "    \n",
    "    print (word,count_Of_Word)\n",
    "    word_index = -1\n",
    "    char_index = 0\n",
    "    \n",
    "    for index in range(0,count_Of_Word):\n",
    "        word_index = string_Output.find(word, word_index + 1)\n",
    "        Min_X = Min_Y = 10000\n",
    "        Max_W = Max_H = 0\n",
    "        \n",
    "        for i in range (word_index, word_index + len(word)):\n",
    "            char = list_Character_Positions[i]\n",
    "            x,y,w,h = char[0],char[1],char[2],char[3]\n",
    "            \n",
    "            if Min_X > x and x > -1:\n",
    "                Min_X = x\n",
    "            if Min_Y > y and y > -1:\n",
    "                Min_Y = y\n",
    "            if Max_W < (x + w):\n",
    "                Max_W = (x + w)\n",
    "            if Max_H < (y + h):\n",
    "                Max_H = (y + h)\n",
    "                \n",
    "            char_index = char_index + 1\n",
    "        cv2.rectangle(image,(Min_X,Min_Y),(Max_W,Max_H),(0,0,0),-1)\n",
    "\n",
    "cv2.imwrite(r'C:\\Users\\sachin13390\\Desktop\\Final.jpg',image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
