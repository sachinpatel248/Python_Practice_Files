{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\product\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_text_summarization.library.utility.plot_utils import plot_and_save_history\n",
    "from keras_text_summarization.library.seq2seq import Seq2SeqGloVeSummarizer\n",
    "from keras_text_summarization.library.applications.fake_news_loader import fit_text\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4515"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_Input_File_Path = r'news_summary_Processed.csv'\n",
    "\n",
    "df = pd.read_csv(csv_Input_File_Path ,encoding = \"latin1\", low_memory = False )\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove NAN rows\n",
    "\n",
    "row_index_To_Delete = []\n",
    "\n",
    "for i, article in enumerate(df['ctext']):\n",
    "    if ( (article != article) or (str(article) == 'nan') ):\n",
    "        row_index_To_Delete.append(i)\n",
    "\n",
    "df = df.drop(df.index[row_index_To_Delete])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3683\n"
     ]
    }
   ],
   "source": [
    "max_Len = 0\n",
    "max_Len_Index = 0\n",
    "\n",
    "for i, article in enumerate(df['ctext']):\n",
    "    if (len(article) > max_Len):\n",
    "        max_Len_Index = i\n",
    "\n",
    "print(len(df['ctext'][max_Len_Index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_File_Path = 'Text_Summarizer_Model.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['ctext']\n",
    "y = df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = fit_text(X, y)\n",
    "\n",
    "summarizer = Seq2SeqGloVeSummarizer(config)\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\product\\python36\\lib\\site-packages\\keras\\engine\\topology.py:2368: UserWarning: Layer decoder_lstm was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'encoder_lstm/while/Exit_2:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'encoder_lstm/while/Exit_3:0' shape=(?, 100) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3516,)\n",
      "(880,)\n",
      "(3516, 500, 100)\n",
      "(880, 500, 100)\n",
      "./models/seq2seq-glove-weights.h5\n",
      "Epoch 1/10\n",
      "219/219 [==============================] - 178s 811ms/step - loss: 4.3646 - acc: 0.0587 - val_loss: 4.2987 - val_acc: 0.0603\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 183s 836ms/step - loss: 4.2456 - acc: 0.0609 - val_loss: 4.2275 - val_acc: 0.0605\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 174s 793ms/step - loss: 4.1545 - acc: 0.0671 - val_loss: 4.1285 - val_acc: 0.0746\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 170s 776ms/step - loss: 4.0379 - acc: 0.0809 - val_loss: 4.0205 - val_acc: 0.0891\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 171s 781ms/step - loss: 3.9192 - acc: 0.0938 - val_loss: 3.9226 - val_acc: 0.0971\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 169s 773ms/step - loss: 3.8154 - acc: 0.1023 - val_loss: 3.8384 - val_acc: 0.1040\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 169s 770ms/step - loss: 3.7282 - acc: 0.1091 - val_loss: 3.7695 - val_acc: 0.1094\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 173s 791ms/step - loss: 3.6531 - acc: 0.1157 - val_loss: 3.7142 - val_acc: 0.1154\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 173s 791ms/step - loss: 3.5877 - acc: 0.1210 - val_loss: 3.6678 - val_acc: 0.1182\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 171s 780ms/step - loss: 3.5295 - acc: 0.1253 - val_loss: 3.6343 - val_acc: 0.1207\n"
     ]
    }
   ],
   "source": [
    "history = summarizer.fit(X_train, y_train, X_test, y_test, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_File_Path = './models/seq2seq-glove-weights.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_Test_File_Path = r'news_summary_Test.csv'\n",
    "\n",
    "df_Test = pd.read_csv(csv_Test_File_Path ,encoding = \"latin1\", low_memory = False )\n",
    "\n",
    "df_Test = df_Test[['Partial_Article_Data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partial_Article_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Australian family has been startled awake a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Partial_Article_Data\n",
       "0  An Australian family has been startled awake a..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_path = './models'\n",
    "very_large_data_dir_path = './very_large_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/seq2seq-glove-weights.h5\n"
     ]
    }
   ],
   "source": [
    "config = np.load(Seq2SeqGloVeSummarizer.get_config_file_path(model_dir_path=model_dir_path)).item()\n",
    "\n",
    "summarizer = Seq2SeqGloVeSummarizer(config)\n",
    "summarizer.load_glove(very_large_data_dir_path)\n",
    "summarizer.load_weights(weight_file_path=Seq2SeqGloVeSummarizer.get_weight_file_path(model_dir_path=model_dir_path))\n",
    "\n",
    "print(Seq2SeqGloVeSummarizer.get_weight_file_path(model_dir_path=model_dir_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the delhi government has been arrested by the delhi of delhi of the delhi government of the delhi government to be the first of the indian government in the state of the indian government in the state of the indian government is a first of the indian government is a\n"
     ]
    }
   ],
   "source": [
    "input_text = df_Test['Partial_Article_Data'][0]\n",
    "\n",
    "text = summarizer.summarize(input_text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An Australian family has been startled awake after a kangaroo crashed its way through a window in their home. The residents managed to trap the marsupial in a bathroom after it \"ran amok\" in the house in Melbourne early on Sunday, a wildlife rescuer said. The family was unharmed, but the distressed kangaroo suffered blood loss and cuts to its paws and legs. Rescuer Manfred Zabinskas said the incident could partly be attributed to homes competing with kangaroo habitats. After being called to the home, Mr Zabinskas found the kangaroo \"fairly exhausted\" in the bathroom, and administered a sedative to remove it safely. \"The family was quite concerned about him because of the amount of blood everywhere,\" he said. He said the \"medium-sized\" kangaroo, weighing about 30kg (65lb), had caused damage across the house and broken a second window while trying to escape. The incident happened on the outskirts of the suburb Deer Park, close to open fields and known kangaroo habitats. Mr Zabinskas said the animal may have been spooked by a dog or a passing car before jumping into the house. \"He would have been in a complete panic and in desperation just run in the path of what would have looked like a passage home, and just gone through the window,\" he told the BBC. \"They do get into trouble in suburbia where we\\'ve got urban areas expanding into the fields where they live.\" The kangaroo has received treatment and is now being cared for by a wildlife rescue service.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test['Partial_Article_Data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
