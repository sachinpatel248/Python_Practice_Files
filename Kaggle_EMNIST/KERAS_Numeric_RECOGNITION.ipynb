{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import string\n",
    "from PIL import Image\n",
    "import csv\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_Train_File_Path = r'C:\\Users\\Sachin\\Desktop\\Kaggle-Emnist\\train.csv'\n",
    "csv_Test_File_Path = r'C:\\Users\\Sachin\\Desktop\\Kaggle-Emnist\\test.csv'\n",
    "csv_Submission_File_Path = r'C:\\Users\\Sachin\\Desktop\\Kaggle-Emnist\\My_Submission8.csv'\n",
    "\n",
    "model_File_Path = r'Keras_Numeric_Model_8.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_Train_File_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(df.columns[0],axis = 1)\n",
    "y = df[df.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (39900, 784)\n",
      "y_train shape (39900,)\n",
      "X_test shape (2100, 784)\n",
      "y_test shape (2100,)\n",
      "Train matrix shape (39900, 784)\n",
      "Test matrix shape (2100, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", Y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", Y_test.shape)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# print the final input shape ready for training\n",
    "print(\"Train matrix shape\", X_train.shape)\n",
    "print(\"Test matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (39900,)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after one-hot encoding:  (39900, 10)\n"
     ]
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train, n_classes )\n",
    "Y_test = np_utils.to_categorical(Y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "X_test = X_test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(784, input_shape=(784,)))\n",
    "# model.add(Activation('relu'))                            \n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(1024))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(10))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, Y_train,\n",
    "#           batch_size=128, epochs=20,\n",
    "#           verbose=2,\n",
    "#           validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "\n",
    "model.add(Dense(512, activation = \"relu\"))\n",
    "\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1)\n",
    "\n",
    "train_datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 42s - loss: 1.1401 - acc: 0.5979 - val_loss: 0.2768 - val_acc: 0.9181\n",
      "Epoch 2/100\n",
      " - 35s - loss: 0.3370 - acc: 0.8940 - val_loss: 0.2535 - val_acc: 0.9129\n",
      "Epoch 3/100\n",
      " - 35s - loss: 0.2363 - acc: 0.9248 - val_loss: 0.1321 - val_acc: 0.9614\n",
      "Epoch 4/100\n",
      " - 37s - loss: 0.1924 - acc: 0.9409 - val_loss: 0.1094 - val_acc: 0.9652\n",
      "Epoch 5/100\n",
      " - 34s - loss: 0.1868 - acc: 0.9390 - val_loss: 0.1397 - val_acc: 0.9548\n",
      "Epoch 6/100\n",
      " - 34s - loss: 0.1506 - acc: 0.9517 - val_loss: 0.1057 - val_acc: 0.9690\n",
      "Epoch 7/100\n",
      " - 34s - loss: 0.1484 - acc: 0.9539 - val_loss: 0.0899 - val_acc: 0.9729\n",
      "Epoch 8/100\n",
      " - 34s - loss: 0.1407 - acc: 0.9521 - val_loss: 0.0924 - val_acc: 0.9710\n",
      "Epoch 9/100\n",
      " - 34s - loss: 0.1337 - acc: 0.9570 - val_loss: 0.0675 - val_acc: 0.9810\n",
      "Epoch 10/100\n",
      " - 34s - loss: 0.0943 - acc: 0.9695 - val_loss: 0.0895 - val_acc: 0.9748\n",
      "Epoch 11/100\n",
      " - 34s - loss: 0.0958 - acc: 0.9705 - val_loss: 0.0745 - val_acc: 0.9762\n",
      "Epoch 12/100\n",
      " - 33s - loss: 0.0953 - acc: 0.9712 - val_loss: 0.0783 - val_acc: 0.9752\n",
      "Epoch 13/100\n",
      " - 33s - loss: 0.0960 - acc: 0.9714 - val_loss: 0.0558 - val_acc: 0.9833\n",
      "Epoch 14/100\n",
      " - 34s - loss: 0.0980 - acc: 0.9695 - val_loss: 0.0426 - val_acc: 0.9867\n",
      "Epoch 15/100\n",
      " - 34s - loss: 0.0812 - acc: 0.9763 - val_loss: 0.0549 - val_acc: 0.9862\n",
      "Epoch 16/100\n",
      " - 34s - loss: 0.0859 - acc: 0.9741 - val_loss: 0.0575 - val_acc: 0.9857\n",
      "Epoch 17/100\n",
      " - 36s - loss: 0.0968 - acc: 0.9695 - val_loss: 0.0831 - val_acc: 0.9724\n",
      "Epoch 18/100\n",
      " - 35s - loss: 0.0812 - acc: 0.9766 - val_loss: 0.0504 - val_acc: 0.9857\n",
      "Epoch 19/100\n",
      " - 34s - loss: 0.0800 - acc: 0.9775 - val_loss: 0.0486 - val_acc: 0.9871\n",
      "Epoch 20/100\n",
      " - 33s - loss: 0.0607 - acc: 0.9790 - val_loss: 0.0574 - val_acc: 0.9852\n",
      "Epoch 21/100\n",
      " - 33s - loss: 0.0760 - acc: 0.9788 - val_loss: 0.0464 - val_acc: 0.9886\n",
      "Epoch 22/100\n",
      " - 35s - loss: 0.0616 - acc: 0.9817 - val_loss: 0.0572 - val_acc: 0.9871\n",
      "Epoch 23/100\n",
      " - 34s - loss: 0.0780 - acc: 0.9771 - val_loss: 0.0935 - val_acc: 0.9729\n",
      "Epoch 24/100\n",
      " - 34s - loss: 0.0742 - acc: 0.9778 - val_loss: 0.0499 - val_acc: 0.9862\n",
      "Epoch 25/100\n",
      " - 39s - loss: 0.0674 - acc: 0.9810 - val_loss: 0.0495 - val_acc: 0.9852\n",
      "Epoch 26/100\n",
      " - 47s - loss: 0.0742 - acc: 0.9766 - val_loss: 0.0470 - val_acc: 0.9862\n",
      "Epoch 27/100\n",
      " - 48s - loss: 0.0643 - acc: 0.9817 - val_loss: 0.0595 - val_acc: 0.9848\n",
      "Epoch 28/100\n",
      " - 49s - loss: 0.0724 - acc: 0.9797 - val_loss: 0.0501 - val_acc: 0.9838\n",
      "Epoch 29/100\n",
      " - 51s - loss: 0.0800 - acc: 0.9775 - val_loss: 0.0419 - val_acc: 0.9871\n",
      "Epoch 30/100\n",
      " - 41s - loss: 0.0558 - acc: 0.9819 - val_loss: 0.0618 - val_acc: 0.9814\n",
      "Epoch 31/100\n",
      " - 51s - loss: 0.0713 - acc: 0.9807 - val_loss: 0.0681 - val_acc: 0.9786\n",
      "Epoch 32/100\n",
      " - 38s - loss: 0.0650 - acc: 0.9797 - val_loss: 0.0564 - val_acc: 0.9843\n",
      "Epoch 33/100\n",
      " - 36s - loss: 0.0679 - acc: 0.9814 - val_loss: 0.0285 - val_acc: 0.9905\n",
      "Epoch 34/100\n",
      " - 36s - loss: 0.0547 - acc: 0.9824 - val_loss: 0.0596 - val_acc: 0.9848\n",
      "Epoch 35/100\n",
      " - 37s - loss: 0.0646 - acc: 0.9795 - val_loss: 0.0331 - val_acc: 0.9881\n",
      "Epoch 36/100\n",
      " - 36s - loss: 0.0574 - acc: 0.9836 - val_loss: 0.0731 - val_acc: 0.9805\n",
      "Epoch 37/100\n",
      " - 35s - loss: 0.0600 - acc: 0.9834 - val_loss: 0.0498 - val_acc: 0.9876\n",
      "Epoch 38/100\n",
      " - 38s - loss: 0.0432 - acc: 0.9888 - val_loss: 0.0429 - val_acc: 0.9881\n",
      "Epoch 39/100\n",
      " - 35s - loss: 0.0577 - acc: 0.9832 - val_loss: 0.0495 - val_acc: 0.9852\n",
      "Epoch 40/100\n",
      " - 40s - loss: 0.0706 - acc: 0.9775 - val_loss: 0.0351 - val_acc: 0.9900\n",
      "Epoch 41/100\n",
      " - 38s - loss: 0.0555 - acc: 0.9836 - val_loss: 0.0418 - val_acc: 0.9886\n",
      "Epoch 42/100\n",
      " - 36s - loss: 0.0423 - acc: 0.9888 - val_loss: 0.0467 - val_acc: 0.9905\n",
      "Epoch 43/100\n",
      " - 36s - loss: 0.0514 - acc: 0.9854 - val_loss: 0.0408 - val_acc: 0.9910\n",
      "Epoch 44/100\n",
      " - 35s - loss: 0.0429 - acc: 0.9866 - val_loss: 0.0525 - val_acc: 0.9871\n",
      "Epoch 45/100\n",
      " - 35s - loss: 0.0620 - acc: 0.9836 - val_loss: 0.0539 - val_acc: 0.9843\n",
      "Epoch 46/100\n",
      " - 38s - loss: 0.0651 - acc: 0.9839 - val_loss: 0.0712 - val_acc: 0.9800\n",
      "Epoch 47/100\n",
      " - 35s - loss: 0.0505 - acc: 0.9849 - val_loss: 0.0349 - val_acc: 0.9919\n",
      "Epoch 48/100\n",
      " - 37s - loss: 0.0561 - acc: 0.9827 - val_loss: 0.0648 - val_acc: 0.9824\n",
      "Epoch 49/100\n",
      " - 36s - loss: 0.0584 - acc: 0.9836 - val_loss: 0.0437 - val_acc: 0.9871\n",
      "Epoch 50/100\n",
      " - 36s - loss: 0.0518 - acc: 0.9844 - val_loss: 0.0353 - val_acc: 0.9895\n",
      "Epoch 51/100\n",
      " - 45s - loss: 0.0412 - acc: 0.9868 - val_loss: 0.0418 - val_acc: 0.9890\n",
      "Epoch 52/100\n",
      " - 59s - loss: 0.0427 - acc: 0.9866 - val_loss: 0.0397 - val_acc: 0.9900\n",
      "Epoch 53/100\n",
      " - 70s - loss: 0.0492 - acc: 0.9885 - val_loss: 0.0322 - val_acc: 0.9919\n",
      "Epoch 54/100\n",
      " - 54s - loss: 0.0462 - acc: 0.9861 - val_loss: 0.0319 - val_acc: 0.9919\n",
      "Epoch 55/100\n",
      " - 38s - loss: 0.0475 - acc: 0.9850 - val_loss: 0.0477 - val_acc: 0.9876\n",
      "Epoch 56/100\n",
      " - 36s - loss: 0.0489 - acc: 0.9861 - val_loss: 0.0375 - val_acc: 0.9895\n",
      "Epoch 57/100\n",
      " - 33s - loss: 0.0412 - acc: 0.9866 - val_loss: 0.0351 - val_acc: 0.9886\n",
      "Epoch 58/100\n",
      " - 33s - loss: 0.0563 - acc: 0.9839 - val_loss: 0.0481 - val_acc: 0.9905\n",
      "Epoch 59/100\n",
      " - 33s - loss: 0.0403 - acc: 0.9893 - val_loss: 0.0533 - val_acc: 0.9852\n",
      "Epoch 60/100\n",
      " - 33s - loss: 0.0643 - acc: 0.9817 - val_loss: 0.0353 - val_acc: 0.9900\n",
      "Epoch 61/100\n",
      " - 33s - loss: 0.0373 - acc: 0.9883 - val_loss: 0.0344 - val_acc: 0.9867\n",
      "Epoch 62/100\n",
      " - 33s - loss: 0.0548 - acc: 0.9856 - val_loss: 0.0389 - val_acc: 0.9886\n",
      "Epoch 63/100\n",
      " - 33s - loss: 0.0369 - acc: 0.9888 - val_loss: 0.0354 - val_acc: 0.9914\n",
      "Epoch 64/100\n",
      " - 33s - loss: 0.0415 - acc: 0.9878 - val_loss: 0.0408 - val_acc: 0.9886\n",
      "Epoch 65/100\n",
      " - 33s - loss: 0.0330 - acc: 0.9900 - val_loss: 0.0283 - val_acc: 0.9910\n",
      "Epoch 66/100\n",
      " - 33s - loss: 0.0460 - acc: 0.9868 - val_loss: 0.0508 - val_acc: 0.9876\n",
      "Epoch 67/100\n",
      " - 38s - loss: 0.0579 - acc: 0.9849 - val_loss: 0.0391 - val_acc: 0.9914\n",
      "Epoch 68/100\n",
      " - 33s - loss: 0.0426 - acc: 0.9863 - val_loss: 0.0477 - val_acc: 0.9895\n",
      "Epoch 69/100\n",
      " - 33s - loss: 0.0513 - acc: 0.9856 - val_loss: 0.0457 - val_acc: 0.9857\n",
      "Epoch 70/100\n",
      " - 32s - loss: 0.0390 - acc: 0.9890 - val_loss: 0.0459 - val_acc: 0.9886\n",
      "Epoch 71/100\n",
      " - 33s - loss: 0.0449 - acc: 0.9868 - val_loss: 0.0393 - val_acc: 0.9886\n",
      "Epoch 72/100\n",
      " - 33s - loss: 0.0500 - acc: 0.9856 - val_loss: 0.0365 - val_acc: 0.9924\n",
      "Epoch 73/100\n",
      " - 33s - loss: 0.0459 - acc: 0.9866 - val_loss: 0.0364 - val_acc: 0.9900\n",
      "Epoch 74/100\n",
      " - 33s - loss: 0.0456 - acc: 0.9844 - val_loss: 0.0362 - val_acc: 0.9886\n",
      "Epoch 75/100\n",
      " - 33s - loss: 0.0381 - acc: 0.9880 - val_loss: 0.0297 - val_acc: 0.9905\n",
      "Epoch 76/100\n",
      " - 34s - loss: 0.0451 - acc: 0.9871 - val_loss: 0.0395 - val_acc: 0.9900\n",
      "Epoch 77/100\n",
      " - 42s - loss: 0.0419 - acc: 0.9895 - val_loss: 0.0304 - val_acc: 0.9919\n",
      "Epoch 78/100\n",
      " - 39s - loss: 0.0388 - acc: 0.9883 - val_loss: 0.0321 - val_acc: 0.9910\n",
      "Epoch 79/100\n",
      " - 37s - loss: 0.0352 - acc: 0.9895 - val_loss: 0.0297 - val_acc: 0.9905\n",
      "Epoch 80/100\n",
      " - 42s - loss: 0.0380 - acc: 0.9893 - val_loss: 0.0247 - val_acc: 0.9948\n",
      "Epoch 81/100\n",
      " - 39s - loss: 0.0271 - acc: 0.9919 - val_loss: 0.0386 - val_acc: 0.9900\n",
      "Epoch 82/100\n",
      " - 34s - loss: 0.0340 - acc: 0.9902 - val_loss: 0.0494 - val_acc: 0.9895\n",
      "Epoch 83/100\n",
      " - 37s - loss: 0.0417 - acc: 0.9875 - val_loss: 0.0342 - val_acc: 0.9914\n",
      "Epoch 84/100\n",
      " - 35s - loss: 0.0421 - acc: 0.9880 - val_loss: 0.0528 - val_acc: 0.9867\n",
      "Epoch 85/100\n",
      " - 33s - loss: 0.0490 - acc: 0.9856 - val_loss: 0.0340 - val_acc: 0.9900\n",
      "Epoch 86/100\n",
      " - 32s - loss: 0.0457 - acc: 0.9873 - val_loss: 0.0421 - val_acc: 0.9910\n",
      "Epoch 87/100\n",
      " - 32s - loss: 0.0365 - acc: 0.9878 - val_loss: 0.0475 - val_acc: 0.9881\n",
      "Epoch 88/100\n",
      " - 32s - loss: 0.0387 - acc: 0.9880 - val_loss: 0.0428 - val_acc: 0.9871\n",
      "Epoch 89/100\n",
      " - 33s - loss: 0.0320 - acc: 0.9905 - val_loss: 0.0360 - val_acc: 0.9910\n",
      "Epoch 90/100\n",
      " - 33s - loss: 0.0349 - acc: 0.9910 - val_loss: 0.0438 - val_acc: 0.9900\n",
      "Epoch 91/100\n",
      " - 33s - loss: 0.0338 - acc: 0.9907 - val_loss: 0.0346 - val_acc: 0.9900\n",
      "Epoch 92/100\n",
      " - 36s - loss: 0.0335 - acc: 0.9919 - val_loss: 0.0416 - val_acc: 0.9900\n",
      "Epoch 93/100\n",
      " - 35s - loss: 0.0373 - acc: 0.9888 - val_loss: 0.0433 - val_acc: 0.9905\n",
      "Epoch 94/100\n",
      " - 33s - loss: 0.0274 - acc: 0.9907 - val_loss: 0.0459 - val_acc: 0.9886\n",
      "Epoch 95/100\n",
      " - 35s - loss: 0.0488 - acc: 0.9880 - val_loss: 0.0254 - val_acc: 0.9914\n",
      "Epoch 96/100\n",
      " - 33s - loss: 0.0365 - acc: 0.9895 - val_loss: 0.0590 - val_acc: 0.9852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 33s - loss: 0.0410 - acc: 0.9868 - val_loss: 0.0358 - val_acc: 0.9905\n",
      "Epoch 98/100\n",
      " - 32s - loss: 0.0282 - acc: 0.9907 - val_loss: 0.0223 - val_acc: 0.9938\n",
      "Epoch 99/100\n",
      " - 34s - loss: 0.0258 - acc: 0.9902 - val_loss: 0.0355 - val_acc: 0.9895\n",
      "Epoch 100/100\n",
      " - 33s - loss: 0.0295 - acc: 0.9922 - val_loss: 0.0287 - val_acc: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25e0bc37f98>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_datagen.flow(X_train, Y_train, batch_size=32),\n",
    "                         validation_data=(X_test, Y_test),\n",
    "                         verbose = 2,\n",
    "                         steps_per_epoch=128, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history = classifier.fit(X_train, Y_train,\n",
    "#           batch_size=128, epochs=20,\n",
    "#           verbose=2,\n",
    "#           validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print (\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(model_File_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KERAS_MODEL = load_model(model_File_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(csv_Test_File_Path)\n",
    "data_frame = data_frame / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns=['ImageId', 'Label']\n",
    "output = []\n",
    "\n",
    "for index in range(len(data_frame)):\n",
    "    image = data_frame.iloc[[index]].values\n",
    "    image = image.reshape(-1, 28,28,1)\n",
    "    \n",
    "    label = KERAS_MODEL.predict_classes(image)\n",
    "    \n",
    "    row = [(index + 1), label[0]]\n",
    "    output.append(row)\n",
    "    \n",
    "ouput_df = pd.DataFrame(output, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ouput_df.to_csv(csv_Submission_File_Path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images processed: 1000\n",
      "Images processed: 2000\n",
      "Images processed: 3000\n",
      "Images processed: 4000\n",
      "Images processed: 5000\n",
      "Images processed: 6000\n",
      "Images processed: 7000\n",
      "Images processed: 8000\n",
      "Images processed: 9000\n",
      "Images processed: 10000\n",
      "Images processed: 11000\n",
      "Images processed: 12000\n",
      "Images processed: 13000\n",
      "Images processed: 14000\n",
      "Images processed: 15000\n",
      "Images processed: 16000\n",
      "Images processed: 17000\n",
      "Images processed: 18000\n",
      "Images processed: 19000\n",
      "Images processed: 20000\n",
      "Images processed: 21000\n",
      "Images processed: 22000\n",
      "Images processed: 23000\n",
      "Images processed: 24000\n",
      "Images processed: 25000\n",
      "Images processed: 26000\n",
      "Images processed: 27000\n",
      "Images processed: 28000\n"
     ]
    }
   ],
   "source": [
    "image_Folder_Path = r'C:\\Users\\Sachin\\Desktop\\Test'\n",
    "\n",
    "Alphabet_Mapping_List = range(0, 10)\n",
    "\n",
    "for alphabet in Alphabet_Mapping_List:\n",
    "    path = image_Folder_Path + '\\\\' + str(alphabet)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "        \n",
    "with open(csv_Test_File_Path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    count = 0\n",
    "    for row in reader:\n",
    "        if (count != 0):\n",
    "            image_array = np.asarray(row)\n",
    "            image_array = image_array.reshape(28, 28)\n",
    "            new_image = Image.fromarray(image_array.astype('uint8'))\n",
    "\n",
    "\n",
    "            digit_Name = ouput_df.iat[count-1,1]\n",
    "#             print (digit_Name)\n",
    "\n",
    "            image_Path = image_Folder_Path + '\\\\' + str(int(digit_Name)) + '\\\\' + str(count) + '.png'\n",
    "            new_image.save(image_Path)\n",
    "        count = count + 1\n",
    "        \n",
    "\n",
    "        if count % 1000 ==0:\n",
    "            print (\"Images processed: \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
